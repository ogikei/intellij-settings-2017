<application>
  <component name="VimSettings">
    <state version="4" enabled="true" />
    <globalmarks />
    <filemarks>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" timestamp="1507706584056">
        <mark key="'" line="105" column="8" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister" timestamp="1507712600296" />
      <file name="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" timestamp="1507703072047">
        <mark key="'" line="256" column="27" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/Source.scala" timestamp="1507711852899">
        <mark key="'" line="65" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark-kinesis-sql-asl/external/kinesis-sql-asl/src/main/scala/org/apache/spark/sql/kinesis/KinesisSource.scala" timestamp="1507708162239">
        <mark key="'" line="57" column="29" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/trees/TreeNode.scala" timestamp="1507710130653" />
      <file name="$USER_HOME$/OfficeTools/git/spark/mllib/src/test/scala/org/apache/spark/ml/feature/MinHashLSHSuite.scala" timestamp="1507700088689">
        <mark key="'" line="30" column="15" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala" timestamp="1507780709726">
        <mark key="'" line="64" column="21" />
        <mark key="[" line="44" column="13" />
        <mark key="]" line="45" column="12" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark-kinesis-sql-asl/external/kinesis-stream-writer/pom.xml" timestamp="1507182933083">
        <mark key="'" line="31" column="15" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVDataSource.scala" timestamp="1507706601691" />
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/QueryTest.scala" timestamp="1507700856945">
        <mark key="'" line="311" column="6" />
      </file>
      <file name="$MAVEN_REPOSITORY$/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar!/au/com/bytecode/opencsv/CSVReader.class" timestamp="1507102694346">
        <mark key="'" line="33" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/streaming/src/test/scala/org/apache/spark/streaming/rdd/WriteAheadLogBackedBlockRDDSuite.scala" timestamp="1507700011532">
        <mark key="'" line="29" column="24" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/RateSourceProvider.scala" timestamp="1507712691727">
        <mark key="'" line="248" column="0" />
        <mark key="[" line="100" column="4" />
        <mark key="]" line="100" column="3" />
        <mark key="." line="100" column="3" />
        <mark key="^" line="100" column="3" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/sources/DataSourceTest.scala" timestamp="1507631886636">
        <mark key="'" line="50" column="14" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/mllib/src/test/scala/org/apache/spark/ml/classification/OneVsRestSuite.scala" timestamp="1507700098337">
        <mark key="[" line="45" column="0" />
        <mark key="]" line="46" column="20" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/kinesis-to-spark/src/main/scala/org/apache/spark/sql/kinesis/DefaultSource.scala" timestamp="1507780680353">
        <mark key="[" line="25" column="6" />
        <mark key="]" line="25" column="12" />
        <mark key="." line="25" column="12" />
        <mark key="^" line="25" column="12" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/kinesis-to-spark/src/main/scala/com/dmm/dre/spark/sql/kinesis/KinesisSourceProvider.scala" timestamp="1507780538119">
        <mark key="[" line="17" column="29" />
        <mark key="]" line="17" column="35" />
        <mark key="." line="17" column="35" />
        <mark key="^" line="17" column="35" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/main/scala/org/apache/spark/sql/SparkSession.scala" timestamp="1507258987259">
        <mark key="'" line="958" column="4" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVFileFormat.scala" timestamp="1507707762817">
        <mark key="'" line="48" column="0" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/StreamingQueryManager.scala" timestamp="1507261019316">
        <mark key="'" line="267" column="26" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/scalastyle-config.xml" timestamp="1507690779639">
        <mark key="'" line="159" column="26" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark-kinesis-sql-asl/scalastyle-config.xml" timestamp="1507183378542">
        <mark key="'" line="21" column="18" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" timestamp="1507703089914">
        <mark key="'" line="328" column="4" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" timestamp="1507284872515">
        <mark key="'" line="143" column="8" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/SQLTestUtils.scala" timestamp="1507714467168" />
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/main/scala/org/apache/spark/sql/Dataset.scala" timestamp="1507260241200">
        <mark key="'" line="390" column="3" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/test/scala/org/apache/spark/sql/kafka010/KafkaSourceSuite.scala" timestamp="1507701612851">
        <mark key="'" line="154" column="9" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/core/src/main/scala/org/apache/spark/ui/UIUtils.scala" timestamp="1507258485942">
        <mark key="'" line="497" column="32" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" timestamp="1507709315436">
        <mark key="'" line="116" column="56" />
        <mark key="[" line="42" column="17" />
        <mark key="]" line="170" column="30" />
        <mark key="^" line="170" column="30" />
        <mark key="." line="170" column="30" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/StreamTest.scala" timestamp="1507701006952">
        <mark key="'" line="241" column="17" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" timestamp="1507709098078">
        <mark key="'" line="278" column="22" />
      </file>
      <file name="$MAVEN_REPOSITORY$/org/apache/spark/spark-streaming_2.11/2.1.0/spark-streaming_2.11-2.1.0-sources.jar!/org/apache/spark/streaming/dstream/DStream.scala" timestamp="1507629720388">
        <mark key="'" line="880" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/sources/interfaces.scala" timestamp="1507690098980">
        <mark key="'" line="151" column="12" />
        <mark key="[" line="210" column="4" />
        <mark key="]" line="182" column="7" />
        <mark key="." line="182" column="7" />
        <mark key="^" line="182" column="7" />
      </file>
      <file name="/sbtShell" timestamp="1507692224425">
        <mark key="[" line="0" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/BatchCommitLog.scala" timestamp="1507710861052">
        <mark key="[" line="49" column="34" />
        <mark key="]" line="49" column="3" />
        <mark key="^" line="49" column="3" />
        <mark key="." line="49" column="3" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/streaming/src/test/scala/org/apache/spark/streaming/rdd/MapWithStateRDDSuite.scala" timestamp="1507697449020">
        <mark key="'" line="29" column="24" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/core/src/test/java/org/apache/spark/io/ReadAheadInputStreamSuite.java" timestamp="1507697880146">
        <mark key="'" line="25" column="13" />
      </file>
      <file name="/HTML File.txt.ft" timestamp="1507689067183">
        <mark key="[" line="0" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister" timestamp="1507704166977">
        <mark key="'" line="5" column="37" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" timestamp="1507703272005">
        <mark key="'" line="146" column="51" />
        <mark key="[" line="91" column="6" />
        <mark key="]" line="91" column="7" />
        <mark key="." line="91" column="7" />
        <mark key="^" line="91" column="7" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaRelation.scala" timestamp="1507708723652" />
      <file name="$USER_HOME$/MyWork/git/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/internal/SQLConf.scala" timestamp="1507187164227">
        <mark key="'" line="739" column="13" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark-kinesis-sql-asl/spark/spark-2.2/kinesis-asl/pom.xml" timestamp="1507106201972">
        <mark key="'" line="80" column="18" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/arithmetic.scala" timestamp="1507257208674">
        <mark key="'" line="260" column="19" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" timestamp="1507622406496">
        <mark key="'" line="295" column="10" />
        <mark key="[" line="71" column="18" />
        <mark key="]" line="71" column="18" />
        <mark key="^" line="71" column="18" />
        <mark key="." line="71" column="18" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" timestamp="1507184992870">
        <mark key="'" line="159" column="19" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark-kinesis-sql-asl/external/kinesis-sql-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisDStreamFunctions.scala" timestamp="1507113156237">
        <mark key="'" line="36" column="25" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" timestamp="1507715022099">
        <mark key="'" line="144" column="2" />
        <mark key="[" line="133" column="0" />
        <mark key="]" line="133" column="0" />
        <mark key="." line="133" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/SharedSQLContext.scala" timestamp="1507701555928">
        <mark key="'" line="0" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/TextSocketStreamSuite.scala" timestamp="1507701324800">
        <mark key="'" line="95" column="66" />
      </file>
      <file name="$USER_HOME$/MyWork/git/spark/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/plans/logical/LogicalPlan.scala" timestamp="1507189169642">
        <mark key="'" line="190" column="32" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/json/JsonSuite.scala" timestamp="1507705055023" />
      <file name="$USER_HOME$/MyWork/git/spark-kinesis-sql-asl/external/kinesis-sql-asl/src/main/scala/org/apache/spark/ml/source/libsvm/LibSVMKinesisValueFormat.scala" timestamp="1507183219756">
        <mark key="'" line="36" column="73" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" timestamp="1507702338306">
        <mark key="'" line="138" column="0" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/spark-kinesis-sql-asl/external/kinesis-sql-asl/src/main/scala/org/apache/spark/sql/kinesis/KinesisSourceProvider.scala" timestamp="1507780482046">
        <mark key="[" line="28" column="0" />
        <mark key="]" line="29" column="41" />
      </file>
      <file name="$USER_HOME$/OfficeTools/git/kinesis-to-spark/src/main/scala/org/apache/spark/sql/kinesis/KinesisSourceProvider.scala" timestamp="1507780591271">
        <mark key="[" line="25" column="44" />
        <mark key="]" line="26" column="1" />
        <mark key="." line="26" column="1" />
        <mark key="^" line="26" column="1" />
      </file>
      <file name="/fragment.java" timestamp="1507780558163">
        <mark key="[" line="0" column="0" />
      </file>
    </filemarks>
    <jumps>
      <jump line="74" column="12" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/TextSocketStreamSuite.scala" />
      <jump line="91" column="31" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/TextSocketStreamSuite.scala" />
      <jump line="92" column="12" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/TextSocketStreamSuite.scala" />
      <jump line="95" column="66" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/streaming/TextSocketStreamSuite.scala" />
      <jump line="62" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" />
      <jump line="40" column="3" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" />
      <jump line="103" column="15" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" />
      <jump line="35" column="18" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" />
      <jump line="63" column="15" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/SharedSQLContext.scala" />
      <jump line="0" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/SharedSQLContext.scala" />
      <jump line="154" column="9" filename="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/test/scala/org/apache/spark/sql/kafka010/KafkaSourceSuite.scala" />
      <jump line="138" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/execution/datasources/csv/CSVSuite.scala" />
      <jump line="69" column="20" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="122" column="0" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="127" column="15" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="128" column="61" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="130" column="60" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="131" column="22" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="256" column="27" filename="$USER_HOME$/OfficeTools/git/spark/external/kinesis-asl/src/main/scala/org/apache/spark/streaming/kinesis/KinesisTestUtils.scala" />
      <jump line="30" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" />
      <jump line="63" column="58" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" />
      <jump line="68" column="50" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" />
      <jump line="70" column="14" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" />
      <jump line="328" column="4" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/FileStreamSource.scala" />
      <jump line="60" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="62" column="6" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="97" column="15" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="104" column="39" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="58" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="57" column="6" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="146" column="51" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/streaming/test/DataStreamReaderWriterSuite.scala" />
      <jump line="58" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="114" column="42" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="119" column="18" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="145" column="51" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="518" column="7" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="0" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="17" column="39" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="35" column="38" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="36" column="38" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="38" column="38" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="52" column="36" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="66" column="77" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="68" column="71" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="6" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister" />
      <jump line="0" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister" />
      <jump line="5" column="37" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/resources/META-INF/services/org.apache.spark.sql.sources.DataSourceRegister" />
      <jump line="322" column="26" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="37" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="65" column="59" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="67" column="67" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="207" column="71" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="319" column="29" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="328" column="60" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="329" column="8" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="105" column="8" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/DataSource.scala" />
      <jump line="48" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/csv/CSVFileFormat.scala" />
      <jump line="57" column="29" filename="$USER_HOME$/OfficeTools/git/spark-kinesis-sql-asl/external/kinesis-sql-asl/src/main/scala/org/apache/spark/sql/kinesis/KinesisSource.scala" />
      <jump line="187" column="19" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="203" column="19" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="3" column="30" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="118" column="6" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="150" column="19" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="375" column="14" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="340" column="9" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="285" column="12" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="278" column="22" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" />
      <jump line="165" column="17" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="216" column="84" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="217" column="68" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="219" column="19" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="220" column="27" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="42" column="16" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="44" column="13" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="45" column="18" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="50" column="43" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="51" column="81" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="62" column="77" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="64" column="10" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="74" column="50" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="79" column="56" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="90" column="50" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="97" column="50" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="104" column="50" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="111" column="65" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="116" column="56" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamReader.scala" />
      <jump line="65" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/Source.scala" />
      <jump line="248" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/main/scala/org/apache/spark/sql/execution/streaming/RateSourceProvider.scala" />
      <jump line="116" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="157" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="510" column="14" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="0" column="0" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="17" column="29" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="25" column="16" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="124" column="34" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="131" column="46" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="132" column="9" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="144" column="2" filename="$USER_HOME$/OfficeTools/git/spark/sql/core/src/test/scala/org/apache/spark/sql/test/DataFrameReaderWriterSuite.scala" />
      <jump line="63" column="0" filename="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala" />
      <jump line="64" column="21" filename="$USER_HOME$/OfficeTools/git/spark/external/kafka-0-10-sql/src/main/scala/org/apache/spark/sql/kafka010/KafkaSourceProvider.scala" />
    </jumps>
    <registers>
      <register name="&quot;" type="4">
        <text>Default</text>
      </register>
      <register name="-" type="4">
        <text>Default</text>
      </register>
      <register name="/" type="4">
        <text>source</text>
      </register>
      <register name="0" type="4">
        <text>tableRelationProvider
    with Logg</text>
      </register>
      <register name="1" type="2">
        <text encoding="base64">ICAK</text>
      </register>
      <register name="2" type="2">
        <text encoding="base64">aW1wb3J0IG9yZy5hcGFjaGUuc3BhcmsuaW50ZXJuYWwuTG9nZ2luZwo=</text>
      </register>
      <register name="3" type="2">
        <text encoding="base64">ICBpbXBvcnQgdGVzdEltcGxpY2l0cy5uZXdCb29sZWFuU2VxRW5jb2Rlcgo=</text>
      </register>
      <register name="4" type="2">
        <text encoding="base64">ICBpbXBvcnQgdGVzdEltcGxpY2l0cy5fCg==</text>
      </register>
      <register name="5" type="2">
        <text encoding="base64">ICAKICBvdmVycmlkZSBkZWYgYmVmb3JlQWxsKCk6IFVuaXQgPSB7CiAgICBzdXBlci5iZWZvcmVBbGwoKQogIH0K</text>
      </register>
      <register name="6" type="2">
        <text encoding="base64">ICBwCg==</text>
      </register>
      <register name="7" type="2">
        <text encoding="base64">ICAgIHZhbCBzcGFyayA9IFNwYXJrQ29udGV4dAo=</text>
      </register>
      <register name="8" type="2">
        <text encoding="base64">Cg==</text>
      </register>
      <register name="9" type="2">
        <text encoding="base64">YWRkU2J0UGx1Z2luKCJjb20uZ2l0aHViLm1wZWx0b25lbiIgJSAic2J0LWlkZWEiICUgIjEuNi4wIikK</text>
      </register>
      <register name=":" type="4">
        <text>w</text>
      </register>
    </registers>
    <search>
      <last-search>source</last-search>
      <last-offset />
      <last-pattern>source</last-pattern>
      <last-replace>&quot;</last-replace>
      <last-substitute>‚Äù</last-substitute>
      <last-dir>1</last-dir>
      <show-last>true</show-last>
    </search>
    <history>
      <history-search>
        <entry>readstream</entry>
        <entry>readd</entry>
        <entry>read</entry>
        <entry>kinesisfunsuite</entry>
        <entry>suite</entry>
        <entry>spark</entry>
        <entry>createsink</entry>
        <entry>defaultsource</entry>
        <entry>default</entry>
        <entry>datasource</entry>
        <entry>relati</entry>
        <entry>relation</entry>
        <entry>option</entry>
        <entry>format</entry>
        <entry>_sqlContext</entry>
        <entry>sqltest</entry>
        <entry>where</entry>
        <entry>test</entry>
        <entry>kinesissource</entry>
        <entry>source</entry>
      </history-search>
      <history-cmd>
        <entry>39</entry>
        <entry>69</entry>
        <entry>44</entry>
        <entry>6</entry>
        <entry>:w</entry>
        <entry>42</entry>
        <entry>17</entry>
        <entry>31</entry>
        <entry>99</entry>
        <entry>104</entry>
        <entry>193</entry>
        <entry>153</entry>
        <entry>26</entry>
        <entry>38</entry>
        <entry>%d</entry>
        <entry>91</entry>
        <entry>102</entry>
        <entry>W</entry>
        <entry>529</entry>
        <entry>w</entry>
      </history-cmd>
      <history-expr />
      <history-input />
    </history>
    <shortcut-conflicts>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed O</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed P</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed E</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed F</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed V</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed A</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed Q</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed B</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed R</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed G</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed H</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed M</text>
      </shortcut-conflict>
      <shortcut-conflict owner="vim">
        <text>ctrl pressed N</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed D</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed T</text>
      </shortcut-conflict>
      <shortcut-conflict owner="ide">
        <text>ctrl pressed I</text>
      </shortcut-conflict>
    </shortcut-conflicts>
    <editor>
      <key-repeat enabled="false" />
    </editor>
  </component>
</application>